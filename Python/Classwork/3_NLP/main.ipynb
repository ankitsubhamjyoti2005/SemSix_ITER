{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e4adabd",
   "metadata": {},
   "source": [
    "# Natural Language Processing [ NLP ]\n",
    "### github : https://github.com/pdeitel/IntroToPython/tree/master/examples/ch12 \n",
    "### book   : http://localhost:8888/files/2241016309/Python/Python%202/Python%20Book.pdf \n",
    "            (only works in lab comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2286ccd5",
   "metadata": {},
   "source": [
    "## TextBlob:  \n",
    "  \n",
    "**TextBlob is an object-oriented NLP text-processing library that is built on the NLTK and\n",
    "pattern NLP libraries and simplifies many of their capabilities**  \n",
    "  \n",
    "**Installing the TextBlob Module:**  \n",
    "To install TextBlob, open your Anaconda Prompt (Windows), Terminal (macOS/Linux) or shell (Linux), then execute the following command:\n",
    "> conda install -c conda-forge textblob  \n",
    "  \n",
    "Windows users might need to run the Anaconda Prompt as an Administrator for proper software installation privileges. To do so, right-click Anaconda Prompt in the start menu and select More > Run as administrator.\n",
    "Once installation completes, execute the following command to download the NLTK corpora used by TextBlob:\n",
    "> ipython -m textblob.download_corpora  \n",
    "  \n",
    "These include:  \n",
    "* The Brown Corpus (created at Brown University4) for parts-of-speech tagging.  \n",
    "* Punkt for English sentence tokenization.  \n",
    "* WordNet for word definitions, synonyms and antonyms.  \n",
    "* Averaged Perceptron Tagger for parts-of-speech tagging.  \n",
    "* conll2000 for breaking text into components, like nouns, verbs, noun phrasesand more—known as chunking the text. The name conll2000 is from the conference that created the chunking data—Conference on Computational Natural Language Learning.  \n",
    "* Movie Reviews for sentiment analysis.  \n",
    "  \n",
    "### **Creating a TextBlob :**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82a0ffd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Today is a beautiful day. Tomorrow looks like bad weather.\")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text = 'Today is a beautiful day. Tomorrow looks like bad weather.'\n",
    "blob = TextBlob(text)\n",
    "\n",
    "blob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8777fdeb",
   "metadata": {},
   "source": [
    "TextBlobs—and, as you’ll see shortly, Sentences and Words—support string methods and can be compared with strings. They also provide methods for various NLP tasks. Sentences, Words and TextBlobs inherit from BaseBlob, so they have many common methods and properties. \n",
    "  \n",
    "### **Tokenizing Text into Sentences and Words :**  \n",
    "Natural language processing often requires tokenizing text before performing other NLP tasks. TextBlob provides convenient properties for accessing the sentences and words in TextBlobs. Let’s use the **sentence property** to get a list of **Sentence** objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4de102d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Today is a beautiful day.\"),\n",
       " Sentence(\"Tomorrow looks like bad weather.\")]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1462b3ae",
   "metadata": {},
   "source": [
    "The **words property** returns a **WordList** object containing a list of **Word** objects, representing each word in the TextBlob with the punctuation removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0892664f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Today', 'is', 'a', 'beautiful', 'day', 'Tomorrow', 'looks', 'like', 'bad', 'weather'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358d3b8",
   "metadata": {},
   "source": [
    "**Question:** Create a TextBlob with two sentences, then tokenize it into Sentences and Words, displaying all the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86177443",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = TextBlob('My old computer is slow. My new one is fast.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afef46ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"My old computer is slow.\"), Sentence(\"My new one is fast.\")]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26d201a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['My', 'old', 'computer', 'is', 'slow', 'My', 'new', 'one', 'is', 'fast'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f91fe9",
   "metadata": {},
   "source": [
    "### Parts-of-Speech Tagging :\n",
    "  \n",
    "**Parts-of-speech (POS) tagging** is the process of evaluating words based on their context\n",
    "to determine each word’s part of speech. There are eight primary English parts of speech—\n",
    "nouns, pronouns, verbs, adjectives, adverbs, prepositions, conjunctions and interjections\n",
    "(words that express emotion and that are typically followed by punctuation, like “Yes!” or\n",
    "“Ha!”). Within each category there are many subcategories.\n",
    "Some words have multiple meanings. For example, the words “set” and “run” have\n",
    "hundreds of meanings each! If you look at the dictionary.com definitions of the word\n",
    "“run,” you’ll see that it can be a verb, a noun, an adjective or a part of a verb phrase. An\n",
    "important use of POS tagging is determining a word’s meaning among its possibly many\n",
    "meanings. This is important for helping computers “understand” natural language.\n",
    "The **tags property** returns a list of tuples, each containing a word and a string representing its part-of-speech tag: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fb12778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Today is a beautiful day. Tomorrow looks like bad weather.\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8cf661b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Today', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('beautiful', 'JJ'),\n",
       " ('day', 'NN'),\n",
       " ('Tomorrow', 'NNP'),\n",
       " ('looks', 'VBZ'),\n",
       " ('like', 'IN'),\n",
       " ('bad', 'JJ'),\n",
       " ('weather', 'NN')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42cd4b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['beautiful day', 'tomorrow', 'bad weather'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.noun_phrases     #extracting nouns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94056b8b",
   "metadata": {},
   "source": [
    "### Sentiment Analysis with TextBlob’s Default Sentiment Analyzer  \n",
    "  \n",
    "One of the most common and valuable NLP tasks is **sentiment analysis**, which determines\n",
    "whether text is positive, neutral or negative. For instance, companies might use this to\n",
    "determine whether people are speaking positively or negatively online about their products. Consider the positive word “good” and the negative word “bad.” Just because a sentence contains “good” or “bad” does not mean the sentence’s sentiment necessarily is\n",
    "positive or negative. For example, the sentence  \n",
    "  \n",
    "> The food is not good.  \n",
    "  \n",
    "clearly has negative sentiment. Similarly, the sentence  \n",
    "  \n",
    "> The movie was not bad.  \n",
    "\n",
    "clearly has positive sentiment, though perhaps not as positive as something like  \n",
    "  \n",
    "> The movie was excellent!  \n",
    "  \n",
    "Sentiment analysis is a complex machine-learning problem. However, libraries like\n",
    "TextBlob have pretrained machine learning models for performing sentiment analysis.  \n",
    "  \n",
    "### Getting the Sentiment of a TextBlob  \n",
    "  \n",
    "A TextBlob’s **sentiment property** returns a **Sentiment**  object indicating whether the text\n",
    "is positive or negative and whether it’s objective or subjective: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59948d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.07500000000000007, subjectivity=0.8333333333333333)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dfcdaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.3f'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " %precision 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2d4a3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.075"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d2ebe1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.833"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d323dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.85, subjectivity=1.0)\n",
      "Sentiment(polarity=-0.6999999999999998, subjectivity=0.6666666666666666)\n"
     ]
    }
   ],
   "source": [
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe9d181c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.35, subjectivity=0.6000000000000001)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Sentence\n",
    "\n",
    "Sentence('The food is not good.').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e13a47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.3499999999999999, subjectivity=0.6666666666666666)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentence('The movie was not bad.').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fbbba92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=1.0, subjectivity=1.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentence('The movie was excellent!').sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa2ad35",
   "metadata": {},
   "source": [
    "### Sentiment Analysis with the NaiveBayesAnalyzer:  \n",
    "By default, a TextBlob and the Sentences and Words you get from it determine sentiment\n",
    "using a PatternAnalyzer, which uses the same sentiment analysis techniques as in the Pattern library. The TextBlob library also comes with a **NaiveBayesAnalyzer** (module **textblob.sentiments**), which was trained on a database of movie reviews. Naive Bayes10 is a\n",
    "commonly used machine learning text-classification algorithm. The following uses the\n",
    "analyzer keyword argument to specify a TextBlob’s sentiment analyzer. Recall from earlier in this ongoing IPython session that text contains 'Today is a beautiful day.\n",
    "Tomorrow looks like bad weather.':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "531eadca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Today is a beautiful day. Tomorrow looks like bad weather.\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "    \n",
    "blob = TextBlob(text, analyzer=NaiveBayesAnalyzer())\n",
    "\n",
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "889066da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='neg', p_pos=0.47662917962091056, p_neg=0.5233708203790892)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bdb9498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(classification='pos', p_pos=0.8117563121751951, p_neg=0.18824368782480477)\n",
      "Sentiment(classification='neg', p_pos=0.174363226578349, p_neg=0.8256367734216521)\n"
     ]
    }
   ],
   "source": [
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec632c5",
   "metadata": {},
   "source": [
    "[ Restart Kernel Here ]  \n",
    "  \n",
    "###  Inflection: Pluralization and Singularization  \n",
    "  \n",
    "**Inflections** are different forms of the same words, such as singular and plural (like “person”\n",
    "and “people”) and different verb tenses (like “run” and “ran”). When you’re calculating\n",
    "word frequencies, you might first want to convert all inflected words to the same form for\n",
    "more accurate word frequencies. Words and WordLists each support converting words to\n",
    "their singular or plural forms. Let’s pluralize and singularize a couple of Word objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e7b0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'indices'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "\n",
    "index = Word('index')\n",
    "\n",
    "index.pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b251c537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cactus'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cacti = Word('cacti')\n",
    "cacti.singularize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2caa369",
   "metadata": {},
   "source": [
    "Pluralizing and singularizing are sophisticated tasks which, as you can see above, are\n",
    "not as simple as adding or removing an “s” or “es” at the end of a word.\n",
    "You can do the same with a WordList: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b198a9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['dogs', 'cats', 'fish', 'birds'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "animals = TextBlob('dog cat fish bird').words\n",
    "animals.pluralize()    #“fish” is the same in both its singular and plural forms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43db846",
   "metadata": {},
   "source": [
    "### Spell Checking and Correction  \n",
    "For natural language processing tasks, it’s important that the text be free of spelling errors.\n",
    "Software packages for writing and editing text, like Microsoft Word, Google Docs and\n",
    "others automatically check your spelling as you type and typically display a red line under\n",
    "misspelled words. Other tools enable you to manually invoke a spelling checker.  \n",
    "  \n",
    "You can check a Word’s spelling with its **spellcheck method**, which returns a list of\n",
    "tuples containing possible correct spellings and a confidence value. Let’s assume we meant\n",
    "to type the word “they” but we misspelled it as “theyr.” The spell checking results show\n",
    "two possible corrections with the word 'they' having the highest confidence value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69f31c24",
   "metadata": {},
   "outputs": [],
   "source": [
    " word = Word('theyr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a243f2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.2f'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%precision 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "967f92ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('they', 0.57), ('their', 0.43)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " word.spellcheck()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16bd1b1",
   "metadata": {},
   "source": [
    "Note that the word with the highest confidence value might not be the correct word for\n",
    "the given context.  \n",
    "  \n",
    "TextBlobs, Sentences and Words all have a **correct method** that you can call to correct spelling. Calling correct on a Word returns the correctly spelled word that has the\n",
    "highest confidence value (as returned by spellcheck):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9236bdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'they'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.correct() # chooses word with the highest confidence value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b293e3d",
   "metadata": {},
   "source": [
    "Calling correct on a TextBlob or Sentence checks the spelling of each word. For each\n",
    "incorrect word, correct replaces it with the correctly spelled one that has the highest confidence value: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72afb991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"The sentence has misspelled words.\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = TextBlob('Ths sentense has missplled wrds.')\n",
    "sentence.correct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac5223",
   "metadata": {},
   "source": [
    "[ Restart Kernel ]  \n",
    "  \n",
    "### Normalization: Stemming and Lemmatization :  \n",
    "  \n",
    "**Stemming** removes a prefix or suffix from a word leaving only a stem, which may or may\n",
    "not be a real word. **Lemmatization** is similar, but factors in the word’s part of speech and\n",
    "meaning and results in a real word.  \n",
    "  \n",
    "Stemming and lemmatization are **normalization** operations, in which you prepare\n",
    "words for analysis. For example, before calculating statistics on words in a body of text,\n",
    "you might convert all words to lowercase so that capitalized and lowercase words are not\n",
    "treated differently. Sometimes, you might want to use a word’s root to represent the word’s\n",
    "many forms. For example, in a given application, you might want to treat all of the following words as “program”: program, programs, programmer, programming and programmed (and perhaps U.K. English spellings, like programmes as well).\n",
    "Words and WordLists each support stemming and lemmatization via the methods\n",
    "**stem** and **lemmatize**. Let’s use both on a Word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af04e6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word\n",
    "    \n",
    "word = Word('varieties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cfa4484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'varieti'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.stem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a82e45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'variety'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.lemmatize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbf34b5",
   "metadata": {},
   "source": [
    "[Restart Kernel]  \n",
    "  \n",
    "### Word Frequencies  \n",
    "  \n",
    "Various techniques for detecting similarity between documents rely on word frequencies.\n",
    "As you’ll see here, TextBlob automatically counts word frequencies. First, let’s load the ebook for Shakespeare’s Romeo and Juliet into a TextBlob. To do so, we’ll use the **Path class** from the Python Standard Library’s **pathlib module**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1a43b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from textblob import TextBlob\n",
    "\n",
    "blob = TextBlob(Path('RomeoAndJuliet.txt').read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d938d2",
   "metadata": {},
   "source": [
    "When you read a file with Path’s **read_text\n",
    "method**, it closes the file immediately after it finishes reading the file.\n",
    "You can access the word frequencies through the TextBlob’s **word_counts dictionary**.\n",
    "Let’s get the counts of several words in the play:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ace1cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.word_counts['juliet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdaa318e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.word_counts['romeo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeb404f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.word_counts['thou']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fecbd6",
   "metadata": {},
   "source": [
    "If you already have tokenized a TextBlob into a WordList, you can count specific\n",
    "words in the list via the **count method**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "091b4930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words.count('joy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63baaf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.noun_phrases.count('lady capulet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d0ea06",
   "metadata": {},
   "source": [
    "[ Restart Kernel ]  \n",
    "  \n",
    "### Getting Definitions, Synonyms and Antonyms from WordNet  \n",
    "  \n",
    "**WordNet** is a word database created by Princeton University. The TextBlob library uses\n",
    "the NLTK library’s WordNet interface, enabling you to look up word definitions, and get\n",
    "synonyms and antonyms. For more information, check out the NLTK WordNet interface\n",
    "documentation at:  \n",
    "  \n",
    "> https://www.nltk.org/api/nltk.corpus.reader.html#modulenltk.corpus.reader.wordnet  \n",
    "  \n",
    "### Getting Definitions  \n",
    "  \n",
    "First, let’s create a Word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83e43d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word\n",
    "\n",
    "happy = Word('happy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ab611b",
   "metadata": {},
   "source": [
    "The Word class’s **definitions property** returns a list of all the word’s definitions in\n",
    "the WordNet database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae03128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enjoying or showing or marked by joy or pleasure',\n",
       " 'marked by good fortune',\n",
       " 'eagerly disposed to act or to be of service',\n",
       " 'well expressed and to the point']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " happy.definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e8ae3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one of 7 to 12 sons of Aditi; Hindu gods of celestial light']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = Word('Aditya')\n",
    "name.definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f937f54d",
   "metadata": {},
   "source": [
    "The database does not necessarily contain every dictionary definition of a given word.\n",
    "There’s also a **define method** that enables you to pass a part of speech as an argument so\n",
    "you can get definitions matching only that part of speech.  \n",
    "  \n",
    "### Getting Synonyms  \n",
    "  \n",
    "You can get a Word’s **synsets**—that is, its sets of synonyms—via the **synsets property**. The\n",
    "result is a list of Synset objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3a3eca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('happy.a.01'),\n",
       " Synset('felicitous.s.02'),\n",
       " Synset('glad.s.02'),\n",
       " Synset('happy.s.04')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy.synsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57115b46",
   "metadata": {},
   "source": [
    "Each Synset represents a group of synonyms. In the notation happy.a.01:\n",
    "* happy is the original Word’s lemmatized form (in this case, it’s the same).  \n",
    "* a is the part of speech, which can be a for adjective, n for noun, v for verb, r for adverb or s for adjective satellite. Many adjective synsets in WordNet have satellite synsets that represent similar adjectives.  \n",
    "* 01 is a 0-based index number. Many words have multiple meanings, and this is the index number of the corresponding meaning in the WordNet database.  \n",
    "  \n",
    "There’s also a **get_synsets method** that enables you to pass a part of speech as an argument so you can get Synsets matching only that part of speech.  \n",
    "  \n",
    "You can iterate through the synsets list to find the original word’s synonyms. Each Synset has a **lemmas method** that returns a list of Lemma objects representing the synonyms. A Lemma’s name method returns the synonymous word as a string. In the following code, for each Synset in the synsets list, the nested for loop iterates through that Synset’s Lemmas (if any). Then we add the synonym to the set named synonyms. We used a set collection because it automatically eliminates any duplicates we add to it: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b981526b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'felicitous', 'glad', 'happy', 'well-chosen'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonyms = set()\n",
    "\n",
    "for synset in happy.synsets:\n",
    "    for lemma in synset.lemmas():\n",
    "        synonyms.add(lemma.name())\n",
    "        \n",
    "synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ae7d1c",
   "metadata": {},
   "source": [
    "### Getting Antonyms  \n",
    "  \n",
    "If the word represented by a Lemma has antonyms in the WordNet database, invoking the\n",
    "Lemma’s antonyms method returns a list of Lemmas representing the antonyms (or an empty\n",
    "list if there are no antonyms in the database). In snippet [4] you saw there were four Synsets for 'happy'. First, let’s get the Lemmas for the Synset at index 0 of the synsets list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "858c387d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('happy.a.01.happy')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas = happy.synsets[0].lemmas()\n",
    "\n",
    "lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38890d59",
   "metadata": {},
   "source": [
    "> In this case, lemmas returned a list of one Lemma element. We can now check whether the database has any corresponding antonyms for that Lemma: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbbc178d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('unhappy.a.01.unhappy')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas[0].antonyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7f5829",
   "metadata": {},
   "source": [
    "> The result is list of Lemmas representing the antonym(s). Here, we see that the one antonym for 'happy' in the database is 'unhappy'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db166d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
